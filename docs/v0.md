# v0 — Protocol Specification

v0 is the bootstrap protocol. It is the only version designed by hand — everything after is proposed and ratified by the network through v0's own mechanisms.

## Table of Contents

1. [Identity](#1-identity)
2. [Message Format](#2-message-format)
3. [Transport](#3-transport)
4. [Peer Discovery](#4-peer-discovery)
5. [Gossip](#5-gossip)
6. [Proposals](#6-proposals)
7. [Votes](#7-votes)
8. [Reputation](#8-reputation)
9. [Sybil Resistance](#9-sybil-resistance)
10. [Anti-Gaming](#10-anti-gaming)
11. [Partition Detection](#11-partition-detection)
12. [Protocol Evolution](#12-protocol-evolution)
13. [Error Handling](#13-error-handling)
14. [Open Questions](#14-open-questions)

---

## 1. Identity

A node is an Ed25519 keypair.

- **Private key:** 32 bytes, Ed25519. Never transmitted.
- **Public key:** 32 bytes, Ed25519. Serves as the node's identity.
- **Node ID:** The hex-encoded public key. This is the canonical identifier.

All messages are signed by the sender's private key. All signatures are verified against the sender's public key.

### Key Operations

| Operation | Algorithm | Input | Output |
|---|---|---|---|
| Sign | Ed25519 | message bytes + private key | 64-byte signature |
| Verify | Ed25519 | message bytes + signature + public key | boolean |

### Key Rotation

A node MAY rotate its keypair by publishing a `KEY_ROTATE` message signed by **both** the old and new keys:

```json
{
  "type": "KEY_ROTATE",
  "payload": {
    "old_key": "<hex_old_public_key>",
    "new_key": "<hex_new_public_key>",
    "new_key_signature": "<hex — payload signed by new private key>"
  }
}
```

The envelope itself is signed by the old key (standard signing). The `new_key_signature` field contains the same payload signed by the new private key. Nodes that verify both signatures MUST update their peer table to associate the old key's reputation with the new key.

**Only one rotation per key:** Nodes MUST accept only the **first** KEY_ROTATE message seen for a given `old_key`. Subsequent KEY_ROTATE messages with the same `old_key` but a different `new_key` MUST be rejected. This prevents reputation cloning via race conditions during gossip propagation.

After rotation, messages signed by the old key MUST be rejected (after a **1-hour** grace period to allow propagation). One hour is conservative — gossip convergence in a healthy network is ~15 minutes. The grace period exists for degraded conditions, not normal operation.

**Tenure continuity:** Key rotation transfers reputation but does NOT reset tenure (§10). The new key inherits the old key's full activity history. Tenure tracks the *identity's* history, not the key's.

### DID Representation (Optional)

Nodes MAY represent their identity as a DID for interoperability:

```
did:valence:<hex-encoded-public-key>
```

The protocol does not require DIDs — the raw public key is sufficient.

---

## 2. Message Format

Every message is a signed JSON envelope.

### Canonicalization

All JSON serialization for signing and hashing MUST follow **RFC 8785 (JSON Canonicalization Scheme — JCS)**:

- Object keys sorted lexicographically by Unicode code point
- No whitespace between tokens
- Numbers serialized per ECMAScript rules (no trailing zeros, no leading plus, etc.)
- Unicode: NFC normalization
- Null values included (not omitted)
- Recursively applied to nested objects

Implementations MUST produce identical byte output for identical logical structures. Failure to canonicalize correctly will cause signature verification failures across implementations.

**Numeric types:** All numeric fields in protocol messages MUST be integers. Floating-point values (reputation scores, etc.) MUST be serialized as integers with fixed precision: **multiply by 10,000 and truncate** (e.g., reputation 0.8 → `8000`, threshold 0.67 → `6700`). This eliminates cross-language float serialization divergence.

### Wire Format

**Stream protocols (point-to-point):** Length-prefixed JSON.

```
+-------------------+-----------------------------+
| 4 bytes (BE u32)  |  JSON payload (UTF-8)       |
| = payload length  |                             |
+-------------------+-----------------------------+
```

Maximum payload size: 8 MiB. Messages exceeding this MUST be rejected.

**GossipSub (broadcast):** Plain UTF-8 JSON. GossipSub handles message boundaries.

### Envelope Schema

```json
{
  "version": 0,
  "type": "<message_type>",
  "id": "<sha256_hex_of_signing_body>",
  "from": "<hex_public_key>",
  "timestamp": <unix_milliseconds>,
  "payload": { ... },
  "signature": "<hex_ed25519_signature>"
}
```

| Field | Type | Description |
|---|---|---|
| `version` | integer | Protocol version. MUST be `0` for this spec. Not included in signing body (see below). |
| `type` | string | Message type. |
| `id` | string | SHA-256 hex digest of the **signing body** (see below). Content address. |
| `from` | string | Hex-encoded Ed25519 public key of the sender. |
| `timestamp` | integer | Unix time in milliseconds when the message was created. |
| `payload` | object | Type-specific payload. |
| `signature` | string | Hex-encoded Ed25519 signature over the signing body bytes. |

### Signing Body

The signature covers the JCS-canonicalized bytes of:

```json
{
  "from": "<from>",
  "payload": <payload>,
  "timestamp": <timestamp>,
  "type": "<type>"
}
```

(Keys in lexicographic order per JCS.)

**Note:** `version` is deliberately excluded from the signing body. This ensures the same logical message has the same `id` and signature regardless of which protocol version it's sent under, preventing message duplication during version transitions.

### Content Addressing

The `id` field is the SHA-256 hex digest of the signing body bytes. Because `id` includes `from` and `timestamp`, two different nodes publishing identical payloads produce different IDs. Messages are deduplicated by `id`.

### Timestamp Validation

Nodes MUST reject messages with timestamps more than **5 minutes** from the node's local time (past or future). This requires loose clock synchronization (NTP). Messages that fail timestamp validation MUST NOT be propagated.

**Clock skew note:** Two nodes both within ±5 minutes of true time can disagree by up to 10 minutes. To prevent this from causing asymmetric message propagation, nodes SHOULD use NTP and SHOULD treat the tolerance as a safety margin, not a target. Nodes with clock skew >2 minutes from the majority of their peers (detected via timestamp comparison in received messages) SHOULD log a warning and attempt clock correction.

---

## 3. Transport

v0 uses libp2p as the transport layer.

### Stream Protocols (Point-to-Point)

| Protocol ID | Purpose |
|---|---|
| `/valence/sync/1.0.0` | Pull-based synchronization and peer exchange |
| `/valence/auth/1.0.0` | Authentication handshake (see below) |

### Authentication Handshake

When two nodes first connect, they exchange an auth challenge over `/valence/auth/1.0.0`:

1. **Initiator** sends `AUTH_CHALLENGE` with a random 32-byte nonce and their own public key
2. **Responder** signs `nonce || initiator_public_key` with their private key and returns `AUTH_RESPONSE`
3. **Initiator** verifies signature (over nonce + own key), VDF proof, and adds peer to table

```json
{"type": "AUTH_CHALLENGE", "payload": {"nonce": "<hex_32_random_bytes>", "initiator_key": "<hex_public_key>"}}
{"type": "AUTH_RESPONSE", "payload": {"signature": "<hex — signs nonce||initiator_key>", "public_key": "<hex>", "vdf_proof": { ... }}}
```

Binding the initiator's key into the signed response prevents replay attacks — an AUTH_RESPONSE is only valid for the specific initiator that issued the challenge.

Nodes MUST complete auth before accepting any other messages from a peer.

### GossipSub Topics (Broadcast)

| Topic | Purpose |
|---|---|
| `/valence/proposals` | New proposals, edits, withdrawals |
| `/valence/votes` | Vote broadcasts |
| `/valence/peers` | Peer discovery announcements |

### NAT Traversal

Nodes SHOULD support libp2p circuit relay v2 for NAT traversal. Nodes with public addresses SHOULD act as relay nodes.

### Connection Security

All connections use libp2p's Noise protocol for encryption and authentication.

---

## 4. Peer Discovery

### Bootstrap

A new node starts with at least one known peer address (a bootstrap node). Bootstrap nodes are regular nodes that happen to be well-known.

Reference implementations MUST include a default bootstrap list. Nodes MAY configure additional or alternative bootstrap nodes.

### Fallback Discovery

When GossipSub-based discovery is unavailable (no connected peers), nodes SHOULD attempt:

1. **mDNS** — discover peers on the local network (for development and LAN deployments)
2. **DNS TXT records** — query a well-known domain for bootstrap peer multiaddrs (e.g., `_valence-bootstrap._tcp.valence.network`)

### Peer Exchange via Sync Protocol

The `/valence/sync/1.0.0` protocol MUST support direct peer list exchange, independent of GossipSub:

```json
{"type": "PEER_LIST_REQUEST", "payload": {"limit": 50, "after": "<node_id | null>"}}
{"type": "PEER_LIST_RESPONSE", "payload": {"peers": [{"node_id": "<hex>", "addresses": ["<multiaddr>"]}], "has_more": true}}
```

Peers are sorted lexicographically by `node_id`. Use `after` for pagination.

This enables a freshly bootstrapped node to discover peers before joining the GossipSub mesh.

### Peer Announcements

Nodes announce on the `/valence/peers` GossipSub topic:

```json
{
  "type": "PEER_ANNOUNCE",
  "payload": {
    "addresses": ["<multiaddr>", ...],
    "capabilities": ["propose", "vote", "store"],
    "version": 0,
    "uptime_seconds": <integer>,
    "vdf_proof": { ... }
  }
}
```

Nodes SHOULD announce every **5 minutes**. Nodes SHOULD prune peers that haven't announced in **30 minutes**.

### Anti-Fragmentation

Nodes MUST periodically connect to random peers outside their immediate neighborhood (suggested: every **10 minutes**). This prevents the network from clustering into disconnected subgraphs.

### ASN Diversity

Nodes MUST track the Autonomous System Number (ASN) distribution of their peers and enforce:

- No single ASN > 25% of connections
- Minimum 4 distinct ASNs (when enough peers are available)

This provides eclipse resistance — an attacker controlling one network segment cannot dominate a node's peer set. ASN diversity is MUST (not SHOULD) because without it, eclipse attacks are trivially cheap (20 nodes across 4 ASNs).

---

## 5. Gossip

### Push

When a node creates or receives a new message, it publishes to the appropriate GossipSub topic.

### Pull (Sync)

Nodes periodically request missed messages from peers via `/valence/sync/1.0.0`:

**Sync Request:**

```json
{
  "type": "SYNC_REQUEST",
  "payload": {
    "since_timestamp": <unix_milliseconds>,
    "since_id": "<message_id — for cursor stability>",
    "types": ["PROPOSE", "VOTE"],
    "limit": 100
  }
}
```

**Sync Response:**

```json
{
  "type": "SYNC_RESPONSE",
  "payload": {
    "messages": [ ... ],
    "has_more": true,
    "next_timestamp": <unix_milliseconds>,
    "next_id": "<message_id>",
    "checkpoint": "<merkle_root_hex>"
  }
}
```

Pagination uses a `(timestamp, id)` cursor to handle multiple messages at the same millisecond deterministically. Sort order: ascending by `timestamp`, then ascending lexicographic by `id`. Messages with `timestamp` > `since_timestamp`, OR (`timestamp` == `since_timestamp` AND `id` > `since_id`), are included.

### Deduplication

Nodes maintain a set of seen message IDs. A message MUST NOT be re-propagated if its `id` has already been seen. Implementations SHOULD use a bounded LRU cache (suggested: **100,000 entries**).

**Time-based rejection (gossip only):** Messages received via GossipSub with timestamps older than **24 hours** MUST be rejected. This prevents replay attacks via cache eviction flooding. This rule does NOT apply to messages received via the `/valence/sync/1.0.0` protocol — sync is explicitly for fetching historical messages (proposals with 14-day voting deadlines, etc.).

---

## 6. Proposals

### Message Types

#### REQUEST

A broadcast need. "I need something."

```json
{
  "type": "REQUEST",
  "payload": {
    "title": "<string>",
    "body": "<string — markdown>",
    "tags": ["<string>", ...],
    "expires": <unix_milliseconds | null>
  }
}
```

#### PROPOSE

A proposed solution. May reference a request, or stand alone.

```json
{
  "type": "PROPOSE",
  "payload": {
    "title": "<string>",
    "body": "<string — markdown description>",
    "content_hash": "<sha256_hex>",
    "content_type": "<mime_type>",
    "content_size": <bytes>,
    "content_url": "<optional — where to fetch the artifact>",
    "content_inline": "<optional — base64, max 1 MiB>",
    "request_id": "<message_id | null — if the referenced request has expired, this proposal still stands on its own>",
    "supersedes": "<message_id | null — previous proposal this replaces>",
    "claims": [
      {
        "statement": "<human-readable claim>",
        "verifiable": <boolean>,
        "evidence": "<optional — URL or description>"
      }
    ],
    "tier": "standard | constitutional",
    "eol": <unix_milliseconds | null>,
    "voting_deadline": <unix_milliseconds>
  }
}
```

**Content delivery:** Small artifacts (< 1 MiB) MAY be inlined as base64 in `content_inline`. Larger artifacts are referenced by `content_hash` and distributed using erasure-coded shards (see below). The hash ensures integrity regardless of source.

**Claims:** Verifiable assertions about the proposal. Signal for evaluation.

**EOL:** Only for protocol change proposals. When the previous protocol version dies.

**Voting deadline:** Required. Proposals MUST specify a deadline (suggested default: 14 days, max: 90 days). Votes received after the deadline MUST NOT be counted.

**Rate limiting:** Nodes are limited to **3 PROPOSE messages per 7-day rolling window**. This prevents spam flooding. Additionally, nodes MUST have reputation ≥ **0.2** (starting rep) to submit proposals — penalized nodes cannot propose until they recover. Nodes SHOULD reject proposals from nodes below starting rep.

#### WITHDRAW

Author withdraws a proposal.

```json
{
  "type": "WITHDRAW",
  "payload": {
    "proposal_id": "<message_id>",
    "reason": "<optional string>"
  }
}
```

Only the original author (verified by `from` key) can withdraw. Nodes MUST stop counting new votes for withdrawn proposals. Nodes that have already locally adopted a proposal are not affected by a later withdrawal.

### Proposal Lifecycle

There is no global state machine. Each node tracks its own view:

- **Open** — proposal exists, votes accumulating, deadline not reached
- **Converging** — weighted endorsement exceeds local threshold
- **Ratified** — node considers the proposal accepted by the network
- **Rejected** — weighted rejection exceeds local threshold, or deadline passed without ratification
- **Adopted** — this specific node has applied the proposal locally and broadcast an ADOPT message
- **Expired** — voting deadline passed
- **Withdrawn** — author withdrew

### Adoption

When a node locally adopts a proposal, it broadcasts an `ADOPT` message:

```json
{
  "type": "ADOPT",
  "payload": {
    "proposal_id": "<message_id>",
    "success": <boolean>,
    "notes": "<optional string>"
  }
}
```

Adoption messages serve as usage attestations — they provide concrete signal that a proposal was applied and whether it worked. They feed into reputation (§8) and help other nodes evaluate proposals.

The `success` field allows nodes to report that they adopted something and it broke — this is valuable negative signal.

**Honest adoption is not provable in v0.** Any node can claim adoption without proof. This is a known limitation. The mitigation is statistical: fabricated adoption messages from colluding nodes will correlate with other collusion indicators (§10). A verifiable adoption mechanism (e.g., proof of execution) can be proposed via the protocol.

### Supersession

Edits to proposals are expressed as new proposals with `supersedes` set to the original proposal's ID. This is simpler than a separate edit mechanism — an edit is just a new proposal that references what it improves. The community votes on the new proposal independently.

### Content Delivery

Large artifacts (> 1 MiB) are distributed using erasure-coded shards across willing peers.

**Erasure coding levels:**

| Level | Data Shards | Parity Shards | Description |
|---|---|---|---|
| minimal | 3 | 2 | 3-of-5 — any 3 shards reconstruct the artifact |
| standard | 5 | 3 | 5-of-8 — default for proposals |
| resilient | 8 | 4 | 8-of-12 — for high-value artifacts |

**Flow:**
1. Proposer erasure-codes the artifact into shards
2. Proposer distributes shards to willing peers (nodes with `"store"` capability)
3. Each shard is content-addressed by its own hash
4. The proposal's `content_hash` is the hash of the original artifact
5. Nodes wanting the artifact request shards from peers, reconstruct with any `data_shards` count of shards

**Shard metadata** is included in the proposal:

```json
"content_shards": {
  "coding": "standard",
  "data_shards": 5,
  "parity_shards": 3,
  "shard_hashes": ["<hex>", ...],
  "shard_size": <bytes>,
  "manifest_hash": "<sha256 of sorted shard_hashes concatenated with content_hash>"
}
```

Nodes storing shards earn reputation via storage challenges (§8).

**Storage challenges** use adjacency proofs rather than shard retrieval. A challenger picks a random offset within a shard and asks: "What is the hash of the N bytes before/after this offset?" This requires the node to actually hold the shard data — it can't answer by fetching the shard on demand because it doesn't know which offset will be challenged. Challenges are fast (hash a small window) and hard to fake without possessing the data.

```json
{"type": "STORAGE_CHALLENGE", "payload": {"shard_hash": "<hex>", "offset": <bytes>, "direction": "before | after", "window_size": <bytes>}}
{"type": "STORAGE_PROOF", "payload": {"proof_hash": "<sha256 of the window bytes>"}}
```

The challenger verifies the proof against their own copy of the shard. **Challengers MUST independently hold the shard they are challenging** — verification by proxy (asking another node for the answer) is vulnerable to collusion rings where confederates pass each other's challenges without storing anything. Challenges SHOULD be issued randomly by peers who hold the same shard, suggested frequency: once per shard per day.

`content_url` remains as a fallback for HTTP-hosted artifacts.

**Shard discovery:** Nodes that store shards announce this via the sync protocol. When a node requests a proposal's content, it can ask any peer "do you have shards for content_hash X?" via a `SHARD_QUERY` / `SHARD_QUERY_RESPONSE` exchange on `/valence/sync/1.0.0`:

```json
{"type": "SHARD_QUERY", "payload": {"content_hash": "<hex>"}}
{"type": "SHARD_QUERY_RESPONSE", "payload": {"available_shards": [0, 3, 5], "shard_hashes": ["<hex>", ...]}}
```

Nodes MAY also gossip shard availability on `/valence/proposals` when they begin storing shards for a proposal.

---

## 7. Votes

### VOTE Message

```json
{
  "type": "VOTE",
  "payload": {
    "proposal_id": "<message_id>",
    "stance": "endorse | reject | abstain",
    "reason": "<optional string>"
  }
}
```

### Vote Rules

- One vote per node per proposal. A second vote from the same `from` key supersedes the first.
- Votes are weighted by the voter's reputation (see §8).
- **Abstain** votes count toward participation quorum but do NOT affect the endorse/reject ratio. This lets nodes signal "I showed up but don't have a strong opinion" without being forced to pick a side. Abstention is particularly important for constitutional proposals where participation quorum matters.
- Nodes MAY vote on their own proposals. The weight is the same.
- Votes received after the proposal's `voting_deadline` MUST NOT be counted.

### Local Evaluation

Each node evaluates proposals independently. Nodes MUST re-evaluate proposal status whenever new votes (including superseding votes) are received. There is no global "this passed" event.

A node considers a proposal ratified when **all**:

1. **Minimum voters:** At least **3** distinct nodes have voted (absolute minimum)
2. **Quorum met:** Total reputation weight of all voters ≥ **quorum_weight** (see below)
3. **Threshold met:**
   ```
   weighted_endorse / (weighted_endorse + weighted_reject) >= local_threshold
   ```

Where:
- `weighted_endorse` = sum of `vote_time_reputation` for all endorse votes
- `weighted_reject` = sum of `vote_time_reputation` for all reject votes
- `vote_time_reputation` = the voter's reputation **at the time the vote was received** (snapshot, not current). Nodes MUST record the voter's reputation when first processing each vote.
- `local_threshold` = configured per-node (suggested default: **0.67**)
- Nodes SHOULD use a higher threshold for protocol change proposals (suggested: **0.80**)

### Network Phases

The network has two governance thresholds. Both require sustained node count AND can be accelerated by genuine activity.

**< 16 nodes:** The protocol is frozen. Content proposals (skills, configs, documents, code) work — that's what the network is for. But **all governance proposals are rejected**. Share, collaborate, build reputation. No rule changes.

**≥ 16 nodes, sustained:** Standard (Tier 1) governance activates. The sustain period depends on network activity:

```
sustain_days = max(3, 7 / activity_multiplier)
```

Where `activity_multiplier` (range 1.0–2.33) is based on:
- Number of content proposals with ≥ 3 distinct ADOPT messages
- Total reputation *earned* network-wide (delta above starting rep, not starting rep itself)
- Distinct node pairs that have exchanged storage challenges

At minimum activity (multiplier 1.0): 7 days. At high activity (multiplier 2.33): 3 days. The floor of 3 days is non-negotiable — gossip convergence and anomaly detection need time.

Activity acceleration does NOT apply to the constitutional threshold.

**≥ 1,024 nodes for 30 consecutive days:** Constitutional (Tier 2) governance activates. No activity acceleration — constitutional governance should be deliberately slow to unlock. The 30-day sustain requirement prevents Sybil-driven threshold gaming.

### Cold Start

For the first **30 days** after standard governance activates (or until any node's reputation exceeds starting rep by 0.1), voting uses **headcount mode**: majority of known nodes must vote, >67% endorse. No reputation weighting. This prevents a tiny number of early grinders from dominating governance before reputation has differentiated.

After cold start ends, weighted voting activates:

- Standard quorum: `max(active_nodes × 0.1, total_known_reputation * 0.10)` (scales with network, floor tied to network size)
- Constitutional quorum: `total_known_reputation * 0.30` (30% of the network's reputation must participate)

### Proposal Tiers

Once critical mass is reached, proposals fall into two tiers:

#### Tier 1: Standard

Skills, configs, documents, code, feature proposals. The normal business of the network.

- **Threshold:** 0.67 weighted endorsement
- **Quorum:** standard quorum weight
- **Voting deadline:** 14 days default, 90 days max

#### Tier 2: Constitutional

Changes to the protocol's core safety properties. A proposal is constitutional if it modifies any of:

- The reputation floor
- Sybil resistance mechanisms (VDF or equivalent)
- The voting threshold or quorum formula
- The constitutional tier itself (meta-governance)
- Key rotation / identity mechanisms
- The critical mass threshold

Constitutional proposals require:

- **Threshold:** 0.90 weighted endorsement
- **Quorum:** 30% of total known network reputation (not a multiplier — a percentage of the whole network)
- **Voting deadline:** 90 days minimum
- **Cooling period:** 30 days between ratification and activation (allows nodes to evaluate and leave if they disagree)

The constitutional tier does NOT make anything immutable — the network can still change these properties. It just requires overwhelming consensus, a long deliberation period, and gives dissenting nodes time to exit.

Below 32 nodes, governance is disabled. At 32, standard governance activates. At 1,024, constitutional governance unlocks and all v0 protocol parameters become Tier 2 protected.

---

## 8. Reputation

### Score

Each node maintains a reputation score for every peer it knows about.

| Field | Type | Description |
|---|---|---|
| `overall` | float | 0.0–1.0. **Hard cap.** Reputation cannot exceed 1.0. |
| `by_domain` | map | Domain-specific scores (e.g., `{"skills": 0.7, "config": 0.4}`) |
| `verification_count` | integer | How many times this peer has verified claims |
| `stake_at_risk` | float | Reputation currently at risk from disputed claims |

### Initial Score

New nodes start at **0.2**. This low starting point means:

- **Below 0.2** = penalized. Clear signal of bad behavior.
- **At 0.2** = new, unproven. Default state.
- **0.3–0.5** = contributing, building trust.
- **0.5+** = established contributor.
- **0.8+** = highly trusted veteran.

The low start ensures that abandoning a penalized identity and re-registering is *always* a loss (any rep above 0.2 is forfeited). It also means earned reputation is clearly distinguishable from default reputation.

### Floor

Reputation cannot drop below **0.1**. This prevents permanent exclusion and allows recovery.

### Earning Reputation

| Action | Reward | Notes |
|---|---|---|
| Proposal adopted by peers | +0.005 per ADOPT message received | Capped at +0.05 per proposal |
| Claim verified true | +0.001 | Confirmation reward |
| Claim found false (by you) | +0.005 | Contradiction reward |
| First to find contradiction | +0.01 | First-finder bonus |
| Storage verified via adjacency challenge | +0.001 per challenge passed | Requires knowledge of shard structure (see below) |
| Uptime (continuous availability) | +0.001 per day | Caps at 30 days accumulation |

### Losing Reputation

| Action | Penalty | Notes |
|---|---|---|
| Proposal with false claims | -0.003 per false claim | Contradiction penalty |
| Failed storage challenge | -0.01 | Claimed to store shard but failed adjacency challenge |
| Collusion detected | -0.05 | See §10 |
| Inactivity | -0.02 per month | After 30 days inactive |

### Velocity Limits

| Limit | Value | Applies |
|---|---|---|
| Maximum daily gain | 0.02 | Above 0.2 (starting score) |
| Maximum weekly gain | 0.08 | Above 0.2 |

**Recovery below starting score is uncapped.** A node penalized below 0.2 can recover at whatever rate their contributions earn, with no daily/weekly cap, until they reach 0.2 again. Above 0.2, velocity limits apply normally.

This completely eliminates identity recycling: re-registering always gives you 0.2, which is the *minimum* any non-penalized node has. There is never an advantage to abandoning an identity.

### Reputation Propagation

Reputation is **locally computed** and **gossip-informed**.

When Node A evaluates Node B's reputation:

1. Start with A's direct observations of B
2. Query peers for their signed assessments of B
3. Weight each peer's assessment by A's trust in that peer
4. Combine:

```
reputation(B) = α × direct_observations(B) + (1-α) × Σ(trust(P) × assessment_P(B)) / Σ(trust(P))
```

Where:
- `α` = **scales with observation count**: `min(0.6, observation_count / 10)`. With 0 direct observations, α = 0 (pure peer assessment). At 6+ observations, α = 0.6. This prevents a "stranger danger" dynamic where unknown nodes are systematically penalized.
- When `α = 0` (no direct observations), `direct_observations(B)` is not used. The node's reputation is entirely peer-informed until direct interaction occurs.
- Sum is over peers P that have shared signed assessments of B
- `trust(P)` = A's direct reputation score for P (NOT recursive — to avoid circular dependency)

Trust is **one level deep**: you trust your peers based on your direct experience with them, and their assessments influence your view of nodes you haven't directly observed.

### Signed Reputation Attestations

Reputation gossip MUST be signed. Each assessment is attributable.

```json
{
  "type": "REPUTATION_GOSSIP",
  "payload": {
    "assessments": [
      {
        "node_id": "<hex_public_key>",
        "overall": <float>,
        "by_domain": { ... },
        "observation_count": <integer>,
        "last_observed": <unix_milliseconds>
      }
    ]
  }
}
```

Because assessments are signed by the sender, they are **attributable and comparable**. If Node A's assessments of C vary significantly when compared by B and D, this is noted but **not automatically penalized** — reputation is locally computed and legitimately changes over time. Instead, signed attestations serve as an audit trail: patterns of extreme or strategic variation can inform collusion detection (§10) but honest temporal variation is expected.

Nodes SHOULD share reputation gossip every **15 minutes**, covering **10 random peers** per message.

---

## 9. Sybil Resistance

### Verifiable Delay Function (VDF)

New nodes MUST compute a VDF proof before participating. This makes mass identity creation expensive.

**Parameters:**
- Algorithm: Iterated SHA-256 (v0). Acknowledged limitation: verification requires recomputation. A proper VDF (Wesolowski/Pietrzak) with fast verification can be proposed via the protocol.
- Difficulty: **1,000,000 iterations** (~30 seconds on commodity hardware)
- Input: The node's public key bytes
- Output: VDF proof (hash chain output + intermediate checkpoints)

**Intermediate checkpoints:** The proof includes hashes at every 100,000th iteration (10 checkpoints). Verifiers MUST verify at least **5 randomly selected segments** (recompute from checkpoint N to checkpoint N+1 and compare). This takes ~15 seconds but provides 99.97% detection rate against single-segment forgery (probability of evading = (5/10)^5 ≈ 3%). Full chain verification (all 10 segments, ~30 seconds) SHOULD be performed for the first peer accepted from each new ASN.

### Registration Flow

1. Generate Ed25519 keypair
2. Compute VDF proof over public key bytes
3. Include proof in auth handshake (§3)
4. Peers verify the proof (spot-check) before accepting the node

### VDF Proof Schema

```json
{
  "output": "<hex>",
  "input_data": "<hex — public key bytes>",
  "difficulty": 1000000,
  "checkpoints": [
    {"iteration": 100000, "hash": "<hex>"},
    {"iteration": 200000, "hash": "<hex>"},
    ...
  ]
}
```

### Rate Limiting

- Maximum 50 VDF verifications per day
- Maximum 5 new peers accepted per hour
- VDF proofs with `input_data` that doesn't match the sender's public key MUST be rejected
- VDF proofs MUST be fresh — verified during the auth handshake, not pre-shared

---

## 10. Anti-Gaming

### Collusion Detection

Nodes SHOULD analyze voting patterns for collusion indicators:

1. **Voting correlation:** Flag groups of 3+ nodes with >95% vote correlation over 20+ proposals
2. **Registration timing:** Flag 3+ nodes whose VDF proofs were computed within a 24-hour window
3. **ASN clustering:** Flag when >25% of active voters share an ASN

Detection is local — each node runs its own analysis. When collusion indicators are found:

- **WARNING severity:** Log, reduce trust in flagged nodes
- **HIGH severity:** Reduce reputation of flagged nodes by 0.05
- **Nodes MAY share collusion alerts** via proposals ("I've detected collusion, here's the evidence, should we act?")

### Tenure Limits

A **voting cycle** is a rolling 30-day window. A node is "active in a cycle" if it has **voted on or had proposals ratified** during that window. This tracks participation broadly, not just proposal authorship — a node that votes on everything but never proposes is still accumulating influence.

Nodes active in 6+ consecutive cycles receive a tenure penalty:

- **5% reduction** in vote weight per cycle after the 6th
- This prevents entrenchment — early participants can't permanently dominate
- Tenure tracks the **identity's history**, not the key. Key rotation (§1) transfers tenure along with reputation — rotating keys does NOT reset tenure
- Skipping a cycle **decays** the tenure counter by 1 (not a full reset). To go from tenure 6 to tenure 3, you must skip 3 cycles (90 days of abstention). This makes gaming expensive — a full reset requires 6 months of inactivity, at which point inactivity decay has also reduced your reputation

### Diversity Scoring

When evaluating proposals, nodes MAY weight votes higher when they come from a diverse set of voters (measured by ASN diversity, federation membership, registration age).

---

## 11. Partition Detection

### Merkle Consistency

Nodes periodically compute a Merkle root over their active proposal set.

**Tree construction:**
- **Leaves:** SHA-256 hash of each active (non-withdrawn, non-expired) proposal's `id`
- **Ordering:** Leaves sorted lexicographically by `id`
- **Structure:** Binary Merkle tree, left-biased for odd leaf counts (last leaf promoted)
- **Hash function:** SHA-256 for internal nodes: `SHA256(left_child || right_child)`

During sync, nodes exchange Merkle roots in `SYNC_RESPONSE`. Divergent roots trigger a partition event.

### Severity Classification

| Condition | Severity |
|---|---|
| < 5% proposal set difference | info |
| 5–20% difference | warning |
| > 20% difference | critical |

### Proposal Retention

The active proposal set MUST be bounded to prevent unbounded growth. Retention policy:

- **Expired proposals** (past `voting_deadline` without ratification): archived after **7 days**
- **Withdrawn proposals:** archived after **7 days**
- **Rejected proposals** (weighted rejection exceeded threshold): archived after **30 days**
- **Ratified proposals:** archived after **180 days** (6 months)
- **Protocol change proposals:** never auto-archived (permanent record)

Archived proposals are removed from the active set and the Merkle tree. Nodes MAY retain archived proposals locally for historical reference but MUST NOT include them in Merkle root computation or sync responses (unless specifically requested).

**Archival is deterministic, not scheduled.** A proposal is archived the instant it meets the retention criteria above. When computing the Merkle root or responding to sync, implementations MUST exclude any proposal whose archival condition is met at the current time. This ensures all nodes agree on the active set at any given moment without coordinating archival schedules.

### Partition Merge

When partitions heal and nodes discover proposals they missed:

1. Sync all missing proposals and votes from both sides
2. Re-evaluate all proposals with the complete vote set (merged votes may change ratification status)
3. For **content proposals** (skills, configs, docs): contradictory ratifications can coexist. Nodes choose locally.
4. For **protocol change proposals**: contradictory ratifications are resolved by **timestamp priority** — the proposal with the earlier `voting_deadline` takes precedence. If deadlines are equal, the proposal with the lower `id` (lexicographic) wins. The losing proposal is re-opened for voting under the merged network's state.

This is a deterministic tie-breaking rule, not a justice system. It ensures all nodes converge to the same protocol state after a partition heals, which is necessary for the network to function. Content proposals don't need this because they don't affect the protocol itself.

---

## 12. Protocol Evolution

### Self-Hosting

v0 governs its own evolution. Protocol changes are **Tier 2 (constitutional) proposals** once the network reaches critical mass. They require:
- `eol` field set (when the previous version dies)
- 0.90 threshold, 30% network quorum, 90-day minimum voting, 30-day cooling period
- Pre-critical-mass: protocol is frozen, no changes possible

### Version Negotiation

Every message carries `"version": 0`. When v1 is ratified, nodes that adopt it start sending `"version": 1`. During the grace period:

1. Nodes MUST accept messages with version N or N+1
2. Nodes MUST respond in the version the peer sent
3. Nodes MUST cleanly reject (not silently corrupt) messages from unrecognized versions

After EOL, nodes on version N stop accepting messages from version N-1 peers.

### Upgrade Path

A protocol change proposal MUST include:
- The complete new specification (or a diff against the current spec)
- The EOL date for the current version
- A migration path

### EOL Timelines

Set by the community as part of the proposal:
- **Minor changes:** 30 days minimum
- **Major changes:** 90+ days minimum

### Constraints

- Changes MUST NOT cause silent misinterpretation between versions during grace period
- Version negotiation MUST cleanly fail rather than corrupt
- The network can evolve into anything it decides — if it decides to suck, that sucks

---

## 13. Error Handling

### Malformed Messages

Messages that fail parsing, signature verification, or timestamp validation MUST be silently dropped. Nodes MUST NOT propagate invalid messages.

### Unknown Message Types

Messages with unrecognized `type` values SHOULD be propagated but not processed, enabling forward compatibility. However, unknown types are subject to **per-sender rate limiting**: nodes MUST NOT propagate more than **10 unknown-type messages per sender per hour**. Messages exceeding this limit are silently dropped. This prevents DoS via garbage message flooding while preserving forward compatibility for legitimate new message types.

### Unknown Fields

Messages with extra fields beyond the schema MUST be accepted (ignore unknown fields). Implementations MUST NOT reject messages with additional fields. This enables extension without protocol version bumps.

### Missing Proposals

When a node receives a VOTE for a proposal it hasn't seen:

1. Store the vote
2. Request the missing proposal from the vote's sender via sync
3. Apply the vote once the proposal arrives

Votes are valid even if they arrive before their proposal (due to gossip ordering).

### Unresponsive Peers

Nodes SHOULD implement exponential backoff for unresponsive peers, with a maximum retry interval of 10 minutes. After 30 minutes without response, the peer SHOULD be pruned from the active peer table (but not forgotten — it can re-announce).

---

## 14. Open Questions

These are acknowledged gaps in v0. They may be addressed by protocol proposals, by operational experience, or by future spec revisions before v0 is finalized.

### Large-Scale Reputation Gossip

At 10,000 nodes, reputation gossip every 15 minutes at 10 assessments each produces ~111 messages/second. Mitigations to consider:
- Adaptive gossip frequency (less frequent as network grows)
- Only gossip about nodes whose reputation changed
- Hierarchical gossip (cluster-level summaries)

This is a scaling problem that doesn't affect bootstrap. Can be addressed by protocol proposal when the network reaches a size where it matters.

### VDF Hardware Heterogeneity

A 30-second VDF on commodity hardware is 3 seconds on a fast server. The difficulty parameter doesn't equalize across hardware. This means well-resourced attackers face a lower cost per identity. Accepted trade-off for v0: it raises the floor, not the ceiling. A proper VDF (Wesolowski/Pietrzak) with verifiable timing can be proposed via the protocol.

### Blacklisting / Banning

v0 has no mechanism to permanently exclude a node. A node with reputation at floor (0.1) can still participate, just with minimal weight. This is intentional — permanent exclusion is antithetical to the protocol's values. Nodes can locally block specific peers at the implementation level. The network can propose a formal ban mechanism if it decides it needs one.

### Constitutional Participation Incentives

The constitutional quorum (30% of network reputation) combined with explicit abstention (§7) ensures meaningful participation. But turnout may still be low without incentives.

Open design questions:
- **Voting incentives:** Should there be a small reputation reward for voting (including abstaining) on constitutional proposals, to drive turnout? Risk: incentivizing uninformed votes. But without it, participation may rely on civic duty alone.
- **Minimum node-count participation:** In addition to the reputation-weighted quorum, should constitutional proposals require a minimum percentage of *nodes* (not just reputation weight) to vote? This prevents a small number of high-rep nodes from meeting quorum alone.

These need to be resolved before the constitutional tier activates (1,024 nodes), not before v0 ships.

### Conformance Test Suite

Not yet written. A set of message exchanges with expected outcomes that any implementation must pass. Critical for interoperability. Should be published alongside the first reference implementation.

### Acknowledged Limitations (By Design)

These are inherent properties of the architecture. They are not bugs — they are trade-offs that come with a subjective, gossip-based consensus system:

- **Vote weight divergence:** The same vote has slightly different weight on different nodes due to gossip latency affecting reputation snapshots. This is inherent to combining local reputation with arrival-time snapshots.
- **Information asymmetry:** Well-connected nodes get fresher reputation data, leading to better decisions and a Matthew effect. Mitigated by anti-fragmentation (§4) but not eliminated.
- **Collusion detection evasion:** Sophisticated colluders can add noise to stay below detection thresholds. The detection catches unsophisticated collusion and raises the cost of coordination.
- **Selective gossip:** A well-connected node can selectively relay votes, subtly influencing which proposals get seen. Anti-fragmentation and diverse connections mitigate but don't eliminate this. Vote receipts ("I've seen vote X" attestations) could be proposed as a network service to make selective relay detectable.
- **Bootstrap founder advantage:** Early nodes accumulate reputation and influence first. The adaptive quorum (§7) and tenure penalties (§10) limit this but don't eliminate it. This is the cost of a permissionless bootstrap.

---

## Constants Summary

| Constant | Value | Context |
|---|---|---|
| Ed25519 key size | 32 bytes (private), 32 bytes (public), 64 bytes (signature) | §1 |
| Key rotation grace period | 1 hour | §1 |
| Canonicalization | RFC 8785 (JCS) | §2 |
| Max message payload | 8 MiB | §2 |
| Timestamp tolerance | ±5 minutes | §2 |
| Inline content limit | 1 MiB | §6 |
| GossipSub topics | 3 | §3 |
| Peer announce interval | 5 minutes | §4 |
| Peer expiry | 30 minutes | §4 |
| Anti-fragmentation interval | 10 minutes | §4 |
| Max ASN fraction | 25% | §4 |
| Min distinct ASNs | 4 | §4 |
| Dedup cache size | 100,000 entries (LRU) | §5 |
| Message max age | 24 hours | §5 |
| Voting deadline default | 14 days | §6 |
| Voting deadline max | 90 days | §6 |
| Minimum voters | 3 | §7 |
| Standard governance threshold | 16 nodes sustained 3-7 days (activity-dependent) | §7 |
| Constitutional governance threshold | 1,024 nodes sustained 30 days | §7 |
| < 16 nodes | frozen (content only) | §7 |
| Cold start period | 30 days after governance activation (headcount voting) | §7 |
| Standard quorum | max(active_nodes × 0.1, total_rep × 0.10) | §7 |
| Standard threshold | 0.67 | §7 |
| Constitutional threshold | 0.90 | §7 |
| Constitutional quorum | 30% of total network reputation | §7 |
| Constitutional voting minimum | 90 days | §7 |
| Constitutional cooling period | 30 days | §7 |
| Default vote threshold | 0.67 | §7 |
| Proposal tiers | standard (0.67), constitutional (0.90) | §7 |
| Initial reputation | 0.2 | §8 |
| Reputation floor | 0.1 | §8 |
| Max daily reputation gain | 0.02 | §8 |
| Max weekly reputation gain | 0.08 | §8 |
| Monthly inactivity decay | 0.02 | §8 |
| Direct observation weight (α) | 0.6 | §8 |
| Reputation gossip interval | 15 minutes | §8 |
| Reputation gossip batch | 10 random peers | §8 |
| VDF verification segments | 5 minimum (of 10) | §9 |
| VDF difficulty | 1,000,000 iterations | §9 |
| VDF checkpoints | every 100,000 iterations | §9 |
| VDF max verifications/day | 50 | §9 |
| Max new peers/hour | 5 | §9 |
| Vote correlation threshold | 95% over 20+ proposals | §10 |
| Reputation hard cap | 1.0 | §8 |
| Recovery below 0.2 | uncapped (no velocity limit) | §8 |
| Direct observation ramp | α = min(0.6, observations/10) | §8 |
| Proposal rate limit | 3 per node per 7 days | §6 |
| Min rep to propose | 0.2 (starting rep) | §6 |
| Vote stances | endorse, reject, abstain | §7 |
| Tenure penalty onset | 6 cycles | §10 |
| Tenure penalty factor | 0.95× per cycle | §10 |
| Tenure decay | -1 per skipped cycle (not full reset) | §10 |
| Collusion penalty | -0.05 | §10 |
| Numeric precision | ×10,000 fixed-point integers | §2 |
| Unknown-type rate limit | 10 per sender per hour | §13 |
| Voting cycle | 30-day rolling window | §10 |
| Minor change EOL minimum | 30 days | §12 |
| Major change EOL minimum | 90 days | §12 |
| Expired proposal archive | 7 days | §6 |
| Withdrawn proposal archive | 7 days | §6 |
| Rejected proposal archive | 30 days | §6 |
| Ratified proposal archive | 180 days | §6 |
| Partition merge rule | timestamp priority for protocol proposals | §11 |
| Default erasure coding | standard (5-of-8) | §6 |
| Peer backoff maximum | 10 minutes | §13 |
